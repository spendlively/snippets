
Задача классификации одежды (Fashion MNIST в Keras)


Архитектура НС
 - модель: Sequential - последовательные слои
 - 2 слоя входной и выходной
 - полносвязная НС: все нейроны текущего слоя
соединены со всеми нейронами предыдущего слоя
 - функции активации: ReLU (входной слой) и SoftMax (выходной слой)

Входные значения
 - интенсивность пиксела в изображении (оттенок серого 0-255 отдельного пиксела)
 - количество значений: 784 (28*28 пикселов)

Входной слой
 - 800 нейронов (можно менять), по 784 входа в каждый нейрон

Выходной слой
 - 10 нейронов (по количеству классов одежды), по 800 входов в каждый нейрон,
(количество нейронов предыдущего слоя)
 - вероятность того, что на изображении данный предмет одежды [0-1]


//Сущности
 - Sequential - модель НС для представления последовательных слоев (идут 1 за 1)
 - Dense - полносвязный тип слоя


//Этапы обучения НС
 - загрузка и подготовка данных
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
# x_train - данные для обучения
# y_train - правильные ответы для обучения

 - подготовка данных для обучения
x_train = x_train.reshape(60000, 784)
x_train /= 255

 - подготовка правильных ответов
y_train = utils.to_categorical(y_train, 10)
classes = ['class1', 'class2', ..., 'class10']

 - определение структуры НС
model = Sequential()
model.add(Dense(800, input_dim=784, activation='relu'))
model.add(Dense(10, activation='softmax'))

 - компиляция (оптимизатор, функция ошибки, метрики качества)
model.compile(loss="categorical_crossentropy", optimizer="SGD", metrics=["accuracy"])

 - обучение НС
model.fit(
    x_train,
    y_train,
    batch_size=200,
    epochs=100,
    verbose=1
)
# x_train - входные данные
# y_train - правильные ответы в формате One-Hot Encoding
# batch_size=200 - размер мини-выборки:
# - берем 200 изображений
# - по ним рассчитываем функцию ошибки
# - рассчитываем градиент
# - меняем веса
# - переходим в кследующей мини-выборке
# epochs=100 = количество эпох обучения
 - 1 эпоха - обучение НС на всем наборе данных (60 000 изображений)

 - распозначание данных
predictions = model.predict(x_train)
print(predictions[0])
print(np.argmax(predictions[0]))
print(np.argmax(y_train[0]))


//Функции активации
 - ReLU - Rectified Linear Unit - полулинейная функция
одна из самы популярных функций для внутренних слоев НС,
т.к. она хорошо работает на практике и ее легко вычислить
f(x) = max(0, x)
если входное значение функции меньше нуля, функция выдает ноль
если входное значение функции больше нуля, функция выдает само это значение

 - SoftMax - нормализованная экспоненциальная фуекция
позволят получить суммарное значение всех нейронов на выходе из слоя равный единице
это позволяет трактовать выход из слоя, использующего такую функцию как вероятность


//Ссылки
Набор данных Fashion MNIST
https://github.com/zalandoresearch/fashion-mnist

Решение
https://github.com/sozykin/dlpython_course/blob/master/introduction/fashion_mnist_dense.ipynb

Ноутбук с полным кодом решения на платформе Google Colab
https://colab.research.google.com/drive/1le7ZWeBnuiufwyN9BVP4QUAZeRg-bTyr


==========================================================================================


//Проблема переобучения



==========================================================================================


