
Что могут делать нейронные сети
 - задачи классификации (определение объекта на фото)
 - задачи регрессии (динамика курса доллара)
 - гугл переводчик
 - автопилот авто
 - генерация музыки
 - генерация изображения по фото


Традиционное машинное обучение
 - необходимо выбрать из большого объема данных те,
которые позволяют решить наши задачи (признаки)
 - выбором признаков занимается человек
 - если признаки выбрать не удается - МО работает плохо


Глубокие нейронные сети
 - один из самых популярных методов машинного обучения
 - нейронная сеть строится из простых вычислительных элементов - искусственных нейронов
 - позволяют автоматически выбрать нужные данные от ненужных (выбирать правильные признаки)
 - НС требуют большой вычислительной мощности


Страница курса - http://www.asozykin.ru/courses/nnpython
Примеры кода - https://www.youtube.com/redirect?q=https%3A%2F%2Fgithub.com%2Fsozykin%2Fdlpython_course&event=video_description&v=GX7qxV5nh5o&redir_token=VHKk7sa0rjdjb7F20ZO-3wYnNA98MTU1ODQwOTEwNEAxNTU4MzIyNzA0


Искусственная нейронная сеть
 - элемент ИНС - искуственный нейрон модели МакКалока-Питтса
 - выходные сигналы одного нейрона передаются на вход другого


Строение искуственного нейрона (МакКалок-Питс)
 - у ИН есть несколько входов (аналог дендридов),
на кот. подаются входные сигналы
 - каждому входу назначается некоторый вес (аналог синапса),
большой вес усиливает сигнал (возбуждающий синапс),
а отрицательный ослабляет (тормозящий синапс)
 - у ИН есть один выход, через который подается выходной сигнал,
(по аналогии с аксоном)
 - выходной сигнал вычисляется по формуле:
выходные сигналы, поступающие на каждый вход умножается на вес,
затем складываются и передается на вход некоторой нелинейной функции активации,
кот. определяет срабатывает нейрон или нет.
 - Функции активации: функция Хевисайда, сигмоидальные функции


Что могут НС
 - приблизить любую функцию с любой заданной точностью
 - проблема: нет конструктивного способа строить сети с заданными свойствами


Слои НС
 - у НС минимум 2 слоя: входной и выходной
 - между входным и выходным слоями могут быть скрытые слои
 - глубокие нейронные сети - НС, которые содержат больше одного скрытого слоя


==========================================================================

Задачи НС
 - классификация (определение объекта на фото)
 - регрессия (динамика курса доллара)


Обучение НС
 - подбор весов таким образом, чтобы сеть решала поставленную задачу


Типы обучения
 - с учителем (на вход подаются данные с правильными ответами)
 - без учителя (на вход подаются данные без правильных ответов)
 - обучение с подкреплением: сеть (агент) получает данные от внешней среды,
правильно ли выполняются действия или неправильно
(в д. курсе рассматривается только подход к обучению "с учителем")


//Сеть "перцептрон" (Франк Розенблатт)
 - метод обучения с учителем
 - выдает сигналы 0 или 1
 - необходим набор входных данных, для которых заранее известен ответ
 - начальные значения весов назначаются случайным образом


Правила обучения перцептрона
 - перцептрон выдает сигналы 0 или 1
 - веса изменяются только если перцептрон выдает неправильный сигнал
 - если выходной сигнал неправильный и равен 0,
входной вектор прибавляется к весам
 - если выходной сигнал неправильный и равен 1,
входной вектор вычитается из весов


Метод использующийся сейчас: обратное распространение ошибки
 - обучение с учителем
 - необходим набор входных данных, для которых заранее известен ответ
 - выходной сигнал - вещественное число (в отличапе от перцептрона)
 - задается мера ошибки, насколько вещественное число, кот. выдает сеть,
отличается от правильного ответа (часто используется среднеквадратичная)
 - обучение строится таким образом, чтобы мера ошибки уменьшалась,
для этого  используется метод минимизации градиентного спуска
 - минимизация ошибки методом стохастического градиентного спуска
 - полное обучение, мини-выборки, онлайн обучение


//Реализации обучения
Полное обучение (неэффективна, если данных много)
 - анализируется ошибка на всех элементах данных
 - считается направление градиента
 - делаем шаг в направлении градиента

Мини-выборки
 - шаг в сторону градиента делается после каждого элемента данных

Онлайн обучение
 - шаг в сторону градиента делается после 10-100 объектов


========================================================================

Библиотеки глубокого обучения
 - TensorFlow (Google)
 - CNTK (Microsoft)
 - cuDNN (реализация на GPU)
 - Caffe
 - torch
 - Keras (позволяет использовать TensorFlow или Theano)
 - Theano
 - DeepLearning4j
