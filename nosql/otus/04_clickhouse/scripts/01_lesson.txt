-- развернем на ВМ
-- диск на 30 гигов, так как будем 10 Гб копировать исходников и потом в БД
gcloud beta compute --project=celtic-house-266612 instances create ch --zone=us-central1-a --machine-type=e2-medium --subnet=default --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=933982307116-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/cloud-platform --image-family=ubuntu-2004-lts --image-project=ubuntu-os-cloud --boot-disk-size=30GB --boot-disk-type=pd-ssd --boot-disk-device-name=mongo --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any

gcloud compute ssh ch

-- установим clickhouse
-- otus$123
sudo apt-get install apt-transport-https ca-certificates dirmngr && sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4 && echo "deb https://repo.clickhouse.com/deb/stable/ main/" | sudo tee  /etc/apt/sources.list.d/clickhouse.list && sudo apt-get update && sudo apt-get install -y clickhouse-server clickhouse-client pv

-- посмотрим bigquery
select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from `bigquery-public-data.chicago_taxi_trips.taxi_trips` group by payment_type order by 3


sudo service clickhouse-server start

-- Проверим статус сервиса
sudo service clickhouse-server status

-- просто так не пустит
clickhouse-client

clickhouse-client --password

show databases;


-- посмотрим на парты
SELECT
    table,
    partition,
    name,
    rows,
    disk_name
FROM system.parts;


-- зальем 10 гигов gs://chicago10
-- https://console.cloud.google.com/storage/browser/chicago10;tab=objects?q=search&referrer=search&prefix=&forceOnObjectsSortingFiltering=false
-- install gcsfuse
-- https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/docs/installing.md

-- есть еще новинка, только для s3 бакет, но быстрее в разы
-- https://github.com/yandex-cloud/geesefs

export GCSFUSE_REPO=gcsfuse-`lsb_release -c -s` && echo "deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main" | sudo tee /etc/apt/sources.list.d/gcsfuse.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo nano /etc/apt/sources.list.d/gcsfuse.list
-- если бы у нас другая версию убунту
-- groovy --> focal
sudo apt update && sudo DEBIAN_FRONTEND=noninteractive apt -y install gcsfuse


sudo su
cd $HOME
mkdir gcsfuse
cd gcsfuse
gcsfuse chicago10 .
-- for umount
-- fusermount -u

-- mkdir chicago
-- cd chicago
ls -l

-- 2 вариант
-- Загрузим 10GB данных в локальную файловую систему из бакета в GCP
-- будем исползовать этот вариант, так как нам нужно будет отредактировать потом файлы
mkdir ~/taxi_data
gsutil -m cp -R gs://chicago10/taxi.csv.0000000000[0-3]* ~/taxi_data/
-- залить все чикагское такси
-- gsutil -m cp -R gs://taxi_trips_2020_10 .

-- Создадим базу данных taxi
clickhouse-client --password=otus\$123
CREATE DATABASE IF NOT EXISTS taxi

CREATE TABLE taxi.taxi_trips
(
    `unique_key` String,
    `taxi_id` String,
    `trip_start_timestamp` DateTime,
    `trip_end_timestamp` DateTime,
    `trip_seconds` Int64,
    `trip_miles` Decimal(10, 4),
    `pickup_census_tract` String,
    `dropoff_census_tract` String,
    `pickup_community_area` String,
    `dropoff_community_area` String,
    `fare` Decimal(10, 4),
    `tips` Decimal(10, 4),
    `tolls` Decimal(10, 4),
    `extras` Decimal(10, 4),
    `trip_total` Decimal(10, 4),
    `payment_type` String,
    `company` String,
    `pickup_latitude` Decimal(10, 4),
    `pickup_longitude` Decimal(10, 4),
    `pickup_location` String,
    `dropoff_latitude` Decimal(10, 4),
    `dropoff_longitude` Decimal(10, 4),
    `dropoff_location` String
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(trip_start_timestamp)
ORDER BY (payment_type, tips, tolls)


-- Пробуем выполнить вставку данных из csv-файлов в созданную таблицу taxi_trips.
cat ./taxi_data/* | pv | clickhouse-client --password=otus\$123 --query 'INSERT INTO taxi.taxi_trips FORMAT CSVWithNames'

Code: 27. DB::ParsingException: Cannot parse input: expected ',' before: 'UTC,2015-08-26 11:15:00 UTC,0,0,,,,,5.85,1.46,0,0,7.31,Credit Card,Chicago Elite Cab Corp. (Chicago Carriag,,,,,,\n6d5b6e5f3e5397f08e770beeb5f34433b0491d12,c2ca6':
Row 1:
Column 0,   name: unique_key,             type: String,         parsed text: "3190243aa353d190bf2e5f366cd61617fa96f6a8"
Column 1,   name: taxi_id,                type: String,         parsed text: "9d4a0cf00e9283302f40800a5da6e7017db07876ff895d9a1ad185fb4b5ba4bc7263e79e5a073a5f147b0dcf5e1f9ce28e149227dcbbea09cc0262d1304b52bc"
Column 2,   name: trip_start_timestamp,   type: DateTime,       parsed text: "2015-08-26 11:15:00"
ERROR: There is no delimiter (,). "U" found instead.

: While executing CSVRowInputFormat: data for INSERT was parsed from stdin: (in query: INSERT INTO taxi.taxi_trips FORMAT CSVWithNames): (at row 1)
. (CANNOT_PARSE_INPUT_ASSERTION_FAILED)

-- Проблема:
В csv-файлах формат даты-времени отличается от формата, допустимого для ClickHouse - присутствует строка "UTC".
Допустимый формат имеет вид: _2015-08-26 11:15:00_. В csv-файлах данные о дате-времени присутсвуют в виде: _2015-08-26 11:15:00 UTC_
-- Решение:
В файлах с даными заменим подстроку "UTC," подстрокой ","
-- Создадим скрипт для замены подстроки "UTC," подстрокой "," в файлах с расширением csv и выполним замену

cd ~/taxi_data
nano crop_utc
#!/bin/bash

for i in *; do
    if [ "${i:0:4}" = "taxi" ];then
        echo "Готовим файл  $i"
        awk '{gsub(/ UTC,/,",")}1' $i > temp.txt && mv temp.txt $i
        tail -n3 $i
    fi
done

chmod +x crop_utc
./crop_utc
-- http://hepd.pnpi.spb.ru/~shevel/Book/node72.html
-- awk '{gsub(/ UTC,/,",")}1' taxi.csv.000000000001 > temp.txt && tail -n3 temp.txt

-- Создадим скрипт вставки данных из 40 csv-файлов в базу taxi_trips
nano insert_data
#!/bin/bash

for i in *; do
    if [ "${i:0:4}" = "taxi" ];then
        echo "Вставляем данные из файла  $i"
        cat $i | clickhouse-client --password=otus\$123 --query 'INSERT INTO taxi.taxi_trips FORMAT CSVWithNames'
    fi
done

-- Выполняем вставку данных:
chmod +x insert_data
./insert_data


-- Подключимся к СУБД СlickHouse и запросим количество записей, добавленных в таблицу taxi_trips
clickhouse-client --password=otus\$123
select count(*) from taxi.taxi_trips

SELECT name, total_rows, total_bytes FROM system.tables where name='taxi_trips' FORMAT Vertical;

-- Выполним оценку времени выполнения эталонного запроса
select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi.taxi_trips group by payment_type order by 3

-- 10 rows in set. Elapsed: 2.026 sec. Processed 26.75 million rows, 841.20 MB (13.20 million rows/s., 415.17 MB/s.)
-- аналогично в Постгресе заняло бы 06 минут 29 секунд
-- В результате оптимизации - создание b-tree покрывающего индекса
-- время выполнения запроса в PostgreSQL сократилось до 8.1 секунд

-- посмотрим физическое расположение файлов
sudo su
cd /var/lib/clickhouse
ls -la

-- размер каталога
du -sh .

-- конфиг
cd /etc/clickhouse-server

SELECT
    table,
    partition,
    name,
    rows,
    disk_name
FROM system.parts;


OPTIMIZE TABLE taxi.taxi_trips FINAL

gcloud compute instances delete ch


-- развернем DBaaS решение на базе ЯО
-- установим cli от ЯО
curl https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash
yc config profile create test
yc init
-- Выбираем тот же профиль
-- Получаем Oauth токен из url и вводим его
-- Выбираем зону по умолчанию (без разницы какую по сути, но надо запомнить какую выбрали!)

-- Будем использовать managed service for clickhouse

-– список кластеров (а вдруг)
yc clickhouse cluster list

-– копируем id зоны, которая соответствует подсети. Понадобится для следующего шага
yc vpc subnet list

-- создадим кластер
yc clickhouse cluster create --name ch --environment=production --network-name default --clickhouse-resource-preset s2.micro --host type=clickhouse,zone-id=ru-central1-a,subnet-id=e9b8sjn002r9quct5fat,assign-public-ip --clickhouse-disk-size 10 --clickhouse-disk-type network-ssd --user name=user1,password=user1password --database name=db1
-- done (6m16s)

-– проверяем что есть кластер и бд
yc clickhouse database list --cluster-name ch


-- Устанавливаем клиент на ноутбук
echo "deb https://repo.clickhouse.tech/deb/stable/ main/" | sudo tee /etc/apt/sources.list.d/clickhouse.list yc config profile create test
sudo apt-get update
sudo apt-get install -y --allow-unauthenticated clickhouse-client

-- Качаем сертификаты для аутентификации
mkdir -p ~/.clickhouse-client /mnt/c/download/clickhouse/ca-certificates/Yandex && \
wget "https://storage.yandexcloud.net/cloud-certs/CA.pem" -O /mnt/c/download/clickhouse/ca-certificates/Yandex/YandexInternalRootCA.crt && \
wget "https://storage.yandexcloud.net/mdb/clickhouse-client.conf.example" -O ~/.clickhouse-client/config.xml

-- Укажите путь к SSL-сертификату в конфигурационном файле, в элементе <caConfig>:
nano ~/.clickhouse-client/config.xml

-- Подключаемся
> clickhouse-client --host  <hostname> \
                  --secure \
                  --user <username> \
                  --database <databasename> \
                  --port 9440 \
                  --ask-password

-- Для подключения к кластеру: host c-<идентификатор кластера>.rw.mdb.yandexcloud.net . И тип кластера zookeeper
c9qogn28jr86o7f45fbr

clickhouse-client --host c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password

show databases
SELECT version();

--загрузим данные
cd /mnt/c/download/clickhouse
curl https://clickhouse-datasets.s3.yandex.net/visits/tsv/visits_v1.tsv.xz | unxz --threads=`nproc` > visits_v1.tsv

clickhouse-client --host c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password \
                  --query "CREATE DATABASE IF NOT EXISTS datasets"

-- Code: 497. DB::Exception: Received from c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net:9440, 51.250.88.166.
-- DB::Exception: user1: Not enough privileges. To execute this query it's necessary to have grant CREATE DATABASE ON datasets.*.

SHOW GRANTS;
GRANT CREATE DATABASE ON datasets.* TO user1;
-- в новой версии не сработало
-- Received exception from server (version 22.8.8):
-- Code: 497. DB::Exception: Received from c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net:9440.
-- DB::Exception: user1: Not enough privileges. To execute this query it's necessary to have grant
-- CREATE DATABASE ON datasets.* WITH GRANT OPTION. (ACCESS_DENIED)

GRANT ALL ON datasets.* TO user1;
-- https://presentations.clickhouse.com/meetup44/RBAC.pdf
-- https://cloud.yandex.ru/docs/managed-clickhouse/operations/cluster-users

-- https://clickhouse.com/docs/ru/getting-started/tutorial/#create-tables
clickhouse-client --host c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password \
                  --query "CREATE TABLE db1.visits_v1 ( CounterID UInt32,  StartDate Date,  Sign Int8,  IsNew UInt8,  VisitID UInt64,  UserID UInt64,  StartTime DateTime,  Duration UInt32,  UTCStartTime DateTime,  PageViews Int32,  Hits Int32,  IsBounce UInt8,  Referer String,  StartURL String,  RefererDomain String,  StartURLDomain String,  EndURL String,  LinkURL String,  IsDownload UInt8,  TraficSourceID Int8,  SearchEngineID UInt16,  SearchPhrase String,  AdvEngineID UInt8,  PlaceID Int32,  RefererCategories Array(UInt16),  URLCategories Array(UInt16),  URLRegions Array(UInt32),  RefererRegions Array(UInt32),  IsYandex UInt8,  GoalReachesDepth Int32,  GoalReachesURL Int32,  GoalReachesAny Int32,  SocialSourceNetworkID UInt8,  SocialSourcePage String,  MobilePhoneModel String,  ClientEventTime DateTime,  RegionID UInt32,  ClientIP UInt32,  ClientIP6 FixedString(16),  RemoteIP UInt32,  RemoteIP6 FixedString(16),  IPNetworkID UInt32,  SilverlightVersion3 UInt32,  CodeVersion UInt32,  ResolutionWidth UInt16,  ResolutionHeight UInt16,  UserAgentMajor UInt16,  UserAgentMinor UInt16,  WindowClientWidth UInt16,  WindowClientHeight UInt16,  SilverlightVersion2 UInt8,  SilverlightVersion4 UInt16,  FlashVersion3 UInt16,  FlashVersion4 UInt16,  ClientTimeZone Int16,  OS UInt8,  UserAgent UInt8,  ResolutionDepth UInt8,  FlashMajor UInt8,  FlashMinor UInt8,  NetMajor UInt8,  NetMinor UInt8,  MobilePhone UInt8,  SilverlightVersion1 UInt8,  Age UInt8,  Sex UInt8,  Income UInt8,  JavaEnable UInt8,  CookieEnable UInt8,  JavascriptEnable UInt8,  IsMobile UInt8,  BrowserLanguage UInt16,  BrowserCountry UInt16,  Interests UInt16,  Robotness UInt8,  GeneralInterests Array(UInt16),  Params Array(String),  Goals Nested(ID UInt32, Serial UInt32, EventTime DateTime,  Price Int64,  OrderID String, CurrencyID UInt32),  WatchIDs Array(UInt64),  ParamSumPrice Int64,  ParamCurrency FixedString(3),  ParamCurrencyID UInt16,  ClickLogID UInt64,  ClickEventID Int32,  ClickGoodEvent Int32,  ClickEventTime DateTime,  ClickPriorityID Int32,  ClickPhraseID Int32,  ClickPageID Int32,  ClickPlaceID Int32,  ClickTypeID Int32,  ClickResourceID Int32,  ClickCost UInt32,  ClickClientIP UInt32,  ClickDomainID UInt32,  ClickURL String,  ClickAttempt UInt8,  ClickOrderID UInt32,  ClickBannerID UInt32,  ClickMarketCategoryID UInt32,  ClickMarketPP UInt32,  ClickMarketCategoryName String,  ClickMarketPPName String,  ClickAWAPSCampaignName String,  ClickPageName String,  ClickTargetType UInt16,  ClickTargetPhraseID UInt64,  ClickContextType UInt8,  ClickSelectType Int8,  ClickOptions String,  ClickGroupBannerID Int32,  OpenstatServiceName String,  OpenstatCampaignID String,  OpenstatAdID String,  OpenstatSourceID String,  UTMSource String,  UTMMedium String,  UTMCampaign String,  UTMContent String,  UTMTerm String,  FromTag String,  HasGCLID UInt8,  FirstVisit DateTime,  PredLastVisit Date,  LastVisit Date,  TotalVisits UInt32,  TraficSource    Nested(ID Int8,  SearchEngineID UInt16, AdvEngineID UInt8, PlaceID UInt16, SocialSourceNetworkID UInt8, Domain String, SearchPhrase String, SocialSourcePage String),  Attendance FixedString(16),  CLID UInt32,  YCLID UInt64,  NormalizedRefererHash UInt64,  SearchPhraseHash UInt64,  RefererDomainHash UInt64,  NormalizedStartURLHash UInt64,  StartURLDomainHash UInt64,  NormalizedEndURLHash UInt64,  TopLevelDomain UInt64,  URLScheme UInt64,  OpenstatServiceNameHash UInt64,  OpenstatCampaignIDHash UInt64,  OpenstatAdIDHash UInt64,  OpenstatSourceIDHash UInt64,  UTMSourceHash UInt64,  UTMMediumHash UInt64,  UTMCampaignHash UInt64,  UTMContentHash UInt64,  UTMTermHash UInt64,  FromHash UInt64,  WebVisorEnabled UInt8,  WebVisorActivity UInt32,  ParsedParams    Nested(Key1 String,  Key2 String,  Key3 String,  Key4 String, Key5 String, ValueDouble    Float64),  Market Nested(Type UInt8, GoalID UInt32, OrderID String,  OrderPrice Int64,  PP UInt32,  DirectPlaceID UInt32,  DirectOrderID  UInt32,  DirectBannerID UInt32,  GoodID String, GoodName String, GoodQuantity Int32,  GoodPrice Int64),  IslandID FixedString(16)) ENGINE = CollapsingMergeTree(Sign) PARTITION BY toYYYYMM(StartDate) ORDER BY (CounterID, StartDate, intHash32(UserID), VisitID) SAMPLE BY intHash32(UserID) SETTINGS index_granularity = 8192"

cat visits_v1.tsv | clickhouse-client --host  c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password \
                  --query "INSERT INTO db1.visits_v1 FORMAT TSV" --max_insert_block_size=100000

-- https://clickhouse.com/docs/ru/sql-reference/statements/optimize/
clickhouse-client --host  c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password \
                  --query "OPTIMIZE TABLE db1.visits_v1 FINAL"

clickhouse-client --host  c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password \
                  --query "SELECT COUNT(*) FROM db1.visits_v1"


-- Example Queries
clickhouse-client --host  c-c9q228dv08qsmu73r0em.rw.mdb.yandexcloud.net \
                  --secure \
                  --user user1 \
                  --database db1 \
                  --port 9440 \
                  --password user1password

SELECT
    StartURL AS URL,
    AVG(Duration) AS AvgDuration
FROM db1.visits_v1
WHERE StartDate BETWEEN '2014-03-23' AND '2014-03-30'
GROUP BY URL
ORDER BY AvgDuration DESC
LIMIT 10


SELECT
    StartURL AS URL,
    AVG(Duration) AS AvgDuration,
    bar(AvgDuration, 0, 200000, 80)
FROM db1.visits_v1
WHERE StartDate BETWEEN '2014-03-23' AND '2014-03-30'
GROUP BY URL
ORDER BY AvgDuration DESC
LIMIT 10


-- подключение из DBeaver/DataGrip
-- https://cloud.yandex.ru/docs/managed-clickhouse/operations/connect?utm_source=console&utm_medium=side-bar-left&utm_campaign=managed-clickhouse
