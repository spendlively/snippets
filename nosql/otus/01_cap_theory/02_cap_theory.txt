
//////////////////////////
//Распределенная система//
//////////////////////////
 - несколько программ работающих на нескольких вычислительных узлах в рамках общей цели
 - НЕТ ЦЕНТРАЛЬНОГО УЗЛА - если вырубить любой компонент системы, система не должна упасть

/////////////////////
//Транзакции и ACID//
/////////////////////
 - последовательность действий, выполняющаяся как единое целое и переводящая базу данных
из одного согласованного состояния в другое согласованное состояние.
 - Транзакция завершается подтверждением изменений (commit) либо откатом изменений (rollback)

//ACID
 - 4 требования к транзакционной системе
//1. Atomicity
 - атомарность
 - выполняется все (commit) или ничего (rollback)
//2. Consistency
 - согласованность
 - данные остаятся в согласованном состоянии - одинаковые на всех узлах
//3. Isolation
 - изолированность
 - транзакции разных пользователей не мешаят друг друга
//4. Durability
 - долговечность, стойкость
 - ничего не потеряется после фиксации транзакции

//Два способа реализации изоляции
//1. блокировки
 - ARIES (Algorithms for Recovery and Isolation Exploiting Semantics) - алгоритмы восстановления систем:
    - logging - запись в журнал всех действий транзакции, которые могут изменить состояние БД;
    - checkpoints - механизм контрольных точек;
    - поддержка покортежных блокировок.
//2. Снимки
 - 2. MVCC (MultiVersion Concurrency Control) - механизм обеспечения параллельного доступа к БД:
    - каждой сессии предоставляется «снимок» БД;
    - изменения в БД невидимы другим пользователям до момента фиксации транзакции

//Проблемы ACID
 - Медленно – каждая транзакция применяется, только если все узлы добавили информацию о ней.
 - Дорого – дата центры должны быть связаны выделенным каналом.
 - Избыточно – такой уровень надежности нужен не всегда
(например, сообщения или фотографии соц. сети).
 - не подходит для распределенных систем

//Чем плох ACID?
 - ACID дорогой и не всегда нужен
 - если нам надо всего лишь:
     - кэшировать значения
     - построить аналитическуя модель
     - поставить лайк
     - загрузить фотку

///////////////
//CAP теорема//
///////////////
//CAP
 – 3 свойства распределенных систем
 - из-за путаницы в интерпретации - добавил оригинальные определения

//1. Consistency - согласованность
 - Every read receives the most recent write or an error
 - Каждое чтение получает самую последнюю запись или ошибку
 - одинаковые данные на всех узлах В ЛЮБОЙ МОМЕНТ ВРЕМЕНИ
 - АСИНХРОННАЯ СИНХРОНИЗАЦИЯ ЛИШАЕТ СИСТЕМУ СОГЛАСОВАННОСТИ
 - если slave отдал устаревшие данные клиенту раньше синхронизации - это ПОТЕРЯ СОГЛАСОВАННОСТИ

//2. Availability - доступность
 - Every request receives a (non-error) response, without the guarantee that it contains the most recent write.
 - Каждый запрос получает ответ (без ошибок), без гарантии того, что он содержит самую последнюю запись.
 - ЛЮБОЙ работающий узел ВСЕГДА выполнит запрос И НА ЧТЕНИЕ И НА ЗАПИСЬ
 - НЕТ гарантии актуальных данных
 - ДАЖЕ ЕСЛИ СИСТЕМА ОТВЕЧАЕТ ЧАС, она считается ДОСТУПНОЙ

//3. Partition Tolerance - устойчивость к разделению сети
 - The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes.
 - Система продолжает работать, несмотря на произвольное количество сообщений, отброшенных (или задержанных) сетью между узлами.
 - система продолжает работать, несмотря на отсутствие связи МЕЖДУ ЛЮБЫМИ УЗЛАМИ
 - ПРИ УСЛОВИИ ЧТО НИ ОДИН УЗЕЛ НЕ УПАЛ

//CAP теорема (Эрик Брьюер 2000г)
 - система может обладать одновременно только 2мя CAP-свойства из 3х

//CА-система
 - не принимаем запросы (не распределенная)
 - реляционные бд обычно относятся к этой категории
 - реляционные субд
 - MySQL, SQL Server, Postgres
//CP-система
 - разрешаем чтение, запрещаем запись (есть консистентность)
 - Neo4J, Google big table, big table derivatives: mongodb hbase, hypertable, redis
//AP-система
 - разрешаем и чтение и запись (есть доступность), данные на разных работающих узлах могут отличаться
 - пример AP системы - DNS, MongoDB
 - amazon dynamo derivatives: cassandra, voldemort, couchdb, riak
//P-система
 -

//Проблемы CAP теоремы:
 - далёкие от реального мира определения
 - в рамках разработки, выбор в основном лежит между CP и AP
 - множество систем — просто P
 - чистые AP и CP системы могут быть не тем, что ожидаешь

//Недостатки, проблема, критика CAP теоремы
//1. Теорема описывает системы слишком упрощенно (AP vs CP).
//2. Каждое понятие возведено в абсолют.
 - Консистентность полная, на всех узлах
 - Доступность не подразумевает частичную доступность узлов
//3. Невозможно достичь идеально CAP для всех операций, но можно выбрать, где какой параметр важнее.
//Вывод
 - cap - штука теоретическая
 - все зависит от того как бд будет настроена

////////
//BASE//
////////

//BASE - альтернатива ACID для распределенных систем
//Basic Availability
 - Система всегда отвечает на запрос, но могут бýтþ несогласованнýе даннýе.
//Soft-state
 - Состоāние системý может менāтþсā со временем даже в
отсутствие запросов клиентов на изменение даннýх. Потому
что в лĀбой момент времени даннýе могут приводитþсā в
согласованное состоāние.
//Eventual consistency
 - конечнаā согласованностþ
 - Система, в конечном итоге, придет в согласованное состоāние,
если даннýе не будут изменāтþсā

//Почитать про CAP-теорему на Хабре
https://habr.com/ru/company/piter/blog/262807/
https://habr.com/ru/post/130577/
https://habr.com/ru/post/328792/
https://habr.com/ru/post/258145/

////////////////////////
//Алгоритмы консенсуса//
////////////////////////
//Проблемы
 - Как распределить изменения по всем узлам?
 - Если есть ведущий узел, но он упал. Как выбрать нового?

//CP. Алгоритм PAXOS
 - Паксос (англ. Paxos) — семейство протоколов для решения задачи
консенсуса в сети ненадёжных вычислителей.
 - семейство алгоритмов
 - Основная проблема — наличие помех в среде передачи данных.
 - Используется для утверждения транзакций в распределённых системах.
 - Не leader-follower (принимать изменения могут разные ноды).
 - Двухфазный коммит.
 - Wikipedia - https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9F%D0%B0%D0%BA%D1%81%D0%BE%D1%81
 - PAXOS demo - http://harry.me/blog/2014/12/27/neat-algorithms-paxos/

//Raft
 - Для обеспечения консенсуса в Raft сначала выбирается лидер, на котором будет лежать
ответственность за управление распределённым логом.
 - Лидер принимает запросы от клиентов и реплицирует их на остальные сервера в кластере.
 - В случае выхода лидера из строя, в кластере будет выбран новый лидер.
     - Leader (лидер) – обрабатывает все клиентские запросы, является source of truth всех данных в
    логе, поддерживает лог фоловеров.
     - Follower (фоловер) – пассивный сервер, который только «слушает» новые записи в лог от
    лидера и редиректит все входящие запросы от клиентов на лидера. По сути, является
    hot-standby репликой лидера.
     - Candidate (кандидат) – специальное состояние сервера, возможное только во время выбора нового лидера.
 - Как сервера договариваются друг с другом: алгоритм распределённого консенсуса Raft
https://habr.com/ru/company/dododev/blog/469999/

//CP. Алгоритм Raft
 - Raft разрабатывался с учётом недостатков PAXOS.
 - Если обычный узел долго не получает сообщений от лидера, то он переходит в состояние
«кандидат» и посылает запрос на голосование. Другие узлы голосуют за того кандидата, от
которого они получили первый запрос.
 - Если кандидат получает сообщение от лидера, то он снимает свою кандидатуру и возвращается
в обычное состояние.
 - Если кандидат получает большинство голосов, то он становится лидером. Если же он не
получил большинства (возникло сразу несколько кандидатов и голоса разделились), то кандидат
ждёт случайное время и инициирует новую процедуру голосования.
 - Процедура голосования повторяется, пока не будет выбран лидер.
 - wiki - https://ru.wikipedia.org/wiki/Raft_(%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC)
 - RAFT demo https://thesecretlivesofdata.com/raf

//AP. Протокол Gossip
 - Протокол Gossip — это протокол для распределенных систем, состоящих из равноправных узлов.
 - Gossip (англ. сплетник) — это группа протоколов, в которых распространение информации идёт
способом, схожим с распространения эпидемий (эпидемический протокол).
 - Gossip-протоколы обеспечивают eventual consistency в распределённой системе. В CAP-теореме
они жертвуют согласованностью, получают доступность и устойчивость к разделению.
 - Основная идея: узлы распространяют информацию об изменениях друг другу по мере возможности,
причём не только самостоятельно добавленные изменения, но и то, что услышали от других узлов
(слухи, gossip). Тогда при отсутствии сбоев рано или поздно все узлы обо всём узнают.
 - Обычно реализуется в форме случайного «однорангового выбора»: с заданной частотой каждый узел
одноранговой сети случайным образом выбирает другой известный ему узел и передаёт тому
обновлённую информацию.
 - wiki - https://ru.wikipedia.org/wiki/Gossip_(%D0%BF%D1%80%D0%BE%D1%82%D0%BE%D0%BA%D0%BE%D0%BB)
 - Scuttlebutt gossip demo https://awinterman.github.io/simple-scuttle


//Что делать?
 - помнить про теорему CAP и ее ограничения;
 - проектирование системы стоит начинать с согласования компромиссов;
 - помнить про ACID / BASE, насколько они применимы к системе;
 - все зависит от проекта, над которым вы работаете.

//Выбор СУБД
1. Объем данных.
2. Размер транзакций: длительность, количество одновременных
транзакций.
3. Количество одновременных соединений/сессий.
4. Соотношение операций чтения/записи.
5. Масштабирование: вертикальное, горизонтальное.
